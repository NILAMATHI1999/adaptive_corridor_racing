# Adaptive Corridor-Aware Racing (ROS2 Humble)

A complete **perception â†’ behaviour â†’ control â†’ SLAM â†’ navigation** pipeline for autonomous racing and indoor robot navigation using **ROS2 Humble**, **Gazebo**, **RViz**, **SLAM (Cartographer)**, and **Navigation2 (Nav2)**.

The robot can:
- simulate LiDAR-based corridor racing,
- explore and map a simulated environment,
- save the generated map,
- reload it for Navigation2,
- navigate autonomously to user-defined goals in Gazebo.

---

# ğŸš€ NEW: Stage 1 â€“ SLAM + Navigation2 (Robot Autonomy)

## ğŸŸ¢ Gazebo Simulation
- TurtleBot3 Burger in `turtlebot3_world`
- LiDAR enabled
- `/scan` used for mapping and planning

## ğŸ”µ SLAM Mapping (Cartographer)
- Ran SLAM to create a 2D occupancy grid map  
- Saved to:
  - `maps/tb3_map.pgm`
  - `maps/tb3_map.yaml`

## ğŸŸ¡ Autonomous Exploration Node (`tb3_auto_explore`)
A custom Python ROS2 node that drives the robot automatically:
- Moves forward for a fixed period  
- Rotates to scan new areas  
- Repeats cycle  
- Enables automated SLAM mapping without teleop

## ğŸ”´ Navigation2 (Nav2)
Using the saved map:
- Loaded map via Map Server  
- Set initial pose in RViz2  
- Planned and executed full navigation goals  
- Robot successfully moved in **Gazebo** following Nav2 global path

Screenshots available in:
```

/docs/screenshots/

```

These include:
- SLAM mapping  
- Nav2 global/local costmaps  
- Navigation goal execution  
- Gazebo robot motion  

---

# ğŸ“¸ Evidence (Screenshots)

**Folder:** `docs/screenshots/`

Contains:
- `rviz_map_loaded.png`
- `rviz_nav2_path.png`
- `rviz_costmap_view.png`
- `rviz_navigation_complete.png`
- `gazebo_environment.png`

These verify that the robot:
- maps the environment,
- loads the map,
- localizes,
- plans a path,
- and navigates successfully in simulation.

---

# ğŸ Stage 2 â€“ Corridor Racing (Perception â†’ Behaviour â†’ Control)

## ğŸŸ¢ Fake LiDAR Node
- Publishes `/scan` with variable corridor widths  
- Simulates transitions: **SAFE â†’ NARROW â†’ CRITICAL**

## ğŸ”µ Perception Node (`racing_perception_node`)
Computes:
- front distance  
- corridor width  
- risk level  
- steering  
- behaviour (CRUISE / SHIFT_LEFT / SHIFT_RIGHT / STOP)

Publishes:
- `/racing/corridor_width`
- `/racing/risk_level`
- `/racing/safe_speed`
- `/racing/steering_cmd`
- `/racing/behavior`

## ğŸ”´ Speed Controller Node
Converts behaviour + safe speed â†’ `/cmd_vel`

## ğŸŸ¡ Data Logger Node
Logs behaviour, speed, steering, and `/cmd_vel` to CSV.

---

# ğŸ— System Architecture

```

Gazebo â†” SLAM â†” Saved Map â†” Nav2
â†“
Perception Node
â†“
Speed Controller
â†“
/cmd_vel
â†“
Robot

```

---

# ğŸ“¦ Project Structure

```

adaptive_corridor_racing/
â”‚
â”œâ”€â”€ racing_perception/          # Corridor perception & behaviour
â”‚
â”œâ”€â”€ maps/                       # Saved SLAM maps (pgm + yaml)
â”‚   â”œâ”€â”€ tb3_map.pgm
â”‚   â””â”€â”€ tb3_map.yaml
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ screenshots/            # RViz & Gazebo evidence
â”‚
â””â”€â”€ tb3_auto_explore/ (optional if added next)

````

---

# â–¶ï¸ How to Run

## 1. Build workspace
```bash
cd ~/ros2_ws
colcon build
source install/setup.bash
````

## 2. Run Gazebo with SLAM (mapping)

```bash
ros2 launch turtlebot3_gazebo turtlebot3_world.launch.py use_sim_time:=True
ros2 launch turtlebot3_cartographer cartographer.launch.py use_sim_time:=True
```

## 3. Run Autonomous Explore Node

```bash
ros2 run tb3_auto_explore auto_explore
```

## 4. Save Map

```bash
ros2 run nav2_map_server map_saver_cli -f ~/tb3_map
```

## 5. Run Navigation2 with Saved Map

```bash
ros2 launch turtlebot3_navigation2 navigation2.launch.py use_sim_time:=True map:=$HOME/tb3_map.yaml
```

---

# ğŸ¯ Why this project is powerful for robotics/research

This project now demonstrates:

### âœ” SLAM mapping

### âœ” Map saving + reuse

### âœ” Nav2 navigation

### âœ” Gazebo simulation

### âœ” RViz visualization

### âœ” Autonomous behaviour design

### âœ” Perception â†’ Control pipeline

### âœ” ROS2 modular coding

### âœ” Real robot navigation logic

This is a **full robotics autonomy system**, suitable for internships, research labs, and RoboRace-style challenges.

````

